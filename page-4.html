<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="utf-8" />
        <!--Busque su emoji en https://www.w3schools.com/html/html_emojis.asp-->
        <title> ü´ßClase 4 </title>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.4/p5.js"></script>
        <script src="https://unpkg.com/ml5@0.20.0-alpha.4/dist/ml5.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.4/p5.js"></script>
        <link rel="stylesheet" href="style.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300..700&display=swap" rel="stylesheet">
    </head>
    <body>
        <header>
            <section>
                <p> 
                    <a href="index.html" >Bienvenido</a> 
                    <a href="page-1.html"> BodyPose</a> 
                    <a href="page-2.html">BodySegmentation</a>
                    <a href="page-3.html">HandPose</a>
                    <a href="page-4.html" class="activo">FaceMesh</a>
                </p>
            </section>
            <h1>FaceMesh</h1>
            <h2></h2>
 

        </header>
        <main>
            <!-- The video feed will be displayed here -->
        </main>
        <aside>
            <button onclick="foto()"> Foto </button>
        </aside>
        <script>
            /*
            * üëã Hello! This is an ml5.js example made and shared with ‚ù§Ô∏è.
            * Learn more about the ml5.js project: https://ml5js.org/
            * ml5.js license and Code of Conduct: https://github.com/ml5js/ml5-next-gen/blob/main/LICENSE.md
            *
            * This example demonstrates face tracking on live video through ml5.faceMesh.
            */

            let faceMesh;
            let video;
            let faces = [];
            let options = { maxFaces: 1, refineLandmarks: false, flipHorizontal: false };

            function preload() {
            // Load the faceMesh model
            faceMesh = ml5.faceMesh(options);
            }

            function setup() {
            createCanvas(640, 480);
            // Create the webcam video and hide it
            video = createCapture(VIDEO);
            video.size(640, 480);
            video.hide();
            // Start detecting faces from the webcam video
            faceMesh.detectStart(video, gotFaces);
            }

            function draw() {
            // Draw the webcam video
            tint(173, 20, 87);
            brightness(80)
            image(video, 0, 0, width, height);

            // Draw all the tracked face points
            for (let i = 0; i < faces.length; i++) {
                let face = faces[i];
                for (let j = 0; j < face.keypoints.length; j++) {
                let keypoint = face.keypoints[j];
                fill(255);
                noStroke();
                circle(keypoint.x, keypoint.y, 3);
                }
            }
            }

            // Callback function for when faceMesh outputs data
            function gotFaces(results) {
            // Save the output to the faces variable
            faces = results;
            }
        </script>
    </body>
</html>